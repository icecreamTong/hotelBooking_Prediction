{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hotel booking-登记的房间类型-多分类任务"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一、读取文件/数据概览"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'hotel_bookings.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-5b6bfcce547e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#一、读取文件/数据概览\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mhotel_bookings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'hotel_bookings.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mhotel_booking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhotel_bookings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhotel_bookings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 946\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1176\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1179\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2007\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2008\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2010\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'hotel_bookings.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#一、读取文件/数据概览\n",
    "hotel_bookings=pd.read_csv('hotel_bookings.csv')\n",
    "hotel_booking=hotel_bookings.copy()\n",
    "print(hotel_bookings.info(),'\\n')\n",
    "print(hotel_bookings.describe(),'\\n')\n",
    "print(hotel_bookings.head(),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二、数据预处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1、为了方便对特征进行one-hot编码，先选出预测值并进行数据编码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=hotel_booking.pop('assigned_room_type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据可视化。预测值Assigned Room Type的比例示意图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import brewer2mpl\n",
    "bmap=brewer2mpl.get_map('Paired','qualitative',12)\n",
    "colors=bmap.mpl_colors\n",
    "size1=y.value_counts()\n",
    "labels=['A','D','E','F','G','C','B','H','I','K','P','L']\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.title('Assigned Room Type')\n",
    "plt.pie(size1,labels=labels,colors=colors,shadow=True,autopct='%.2f%%')\n",
    "plt.axis=('equal')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping={'A':1,'B':2,'C':3,'D':4,'E':5,'F':6,'G':7,'H':8,'I':9,'K':11,'L':12,'P':16}\n",
    "y=y.map(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2、缺失值处理，用上下条数据填充。对于'company'列，由于缺失了94.3%，缺失量过多，故删除该特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#缺失值处理，用上下条数据填充。\n",
    "hotel_booking['children'].fillna(method='backfill',inplace=True)\n",
    "hotel_booking['country'].fillna(method='backfill',inplace=True)\n",
    "hotel_booking['agent'].fillna(method='backfill',inplace=True)\n",
    "#对于'company'列，由于缺失了94.3%，缺失量过多，故删除该特征。\n",
    "hotel_booking = hotel_booking.drop(['company'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3、特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#特征工程\n",
    "#1、数据编码（映射的方式）\n",
    "hotel_booking_f=hotel_bookings.copy()\n",
    "hotel_booking_f['children'].fillna(method='backfill',inplace=True)\n",
    "hotel_booking_f['country'].fillna(method='backfill',inplace=True)\n",
    "hotel_booking_f['agent'].fillna(method='backfill',inplace=True)\n",
    "hotel_booking_f= hotel_booking.drop(['company','reservation_status_date'],axis=1)\n",
    "\n",
    "mapping1 = {'City Hotel': 0, 'Resort Hotel': 1}\n",
    "hotel_booking_f['hotel'] = hotel_booking_f['hotel'].map(mapping1)\n",
    "mapping2={'January':1,'February':2,'March':3,'April':4,'May':5,'June':6,\n",
    "          'July':7,'August':8,'September':9,'October':10,'November':11,'December':12}\n",
    "hotel_booking_f['arrival_date_month'] = hotel_booking_f['arrival_date_month'].map(mapping2)\n",
    "mapping3={'BB':1,'HB':2,'SC':3,'FB':4,'Undefined':0}\n",
    "hotel_booking_f['meal'] = hotel_booking_f['meal'].map(mapping3)\n",
    "mapping4={'PRT':1,'GBR':2,'FRA':3,'ESP':4,'DEU':5}\n",
    "hotel_booking_f['country'] = hotel_booking_f['country'].map(mapping4)\n",
    "mapping5={'Online TA':1,'Offline TA/TO':2,'Groups':3,'Direct':4,'Corporate':5,'Complementary':6,'Aviation':7,'Undefined':8}\n",
    "hotel_booking_f['market_segment'] = hotel_booking_f['market_segment'].map(mapping5)\n",
    "mapping6={'TA/TO':1,'Direct':2,'Corporate':3,'GDS':4,'Undefined':5}\n",
    "hotel_booking_f['distribution_channel'] = hotel_booking_f['distribution_channel'].map(mapping6)\n",
    "mapping7={'A':1,'B':2,'C':3,'D':4,'E':5,'F':6,'G':7,'H':8,'L':12,'P':16}\n",
    "hotel_booking_f['reserved_room_type'] = hotel_booking_f['reserved_room_type'].map(mapping7)\n",
    "mapping8={'A':1,'B':2,'C':3,'D':4,'E':5,'F':6,'G':7,'H':8,'I':9,'K':11,'L':12,'P':16}\n",
    "hotel_booking_f['assigned_room_type'] = hotel_booking_f['assigned_room_type'].map(mapping8)\n",
    "mapping9={'No Deposit':1,'Non Refund':2,'Refundable':3}\n",
    "hotel_booking_f['deposit_type'] = hotel_booking_f['deposit_type'].map(mapping9)\n",
    "mapping10={'Transient':1,'Transient-Party':2,'Contract':3,'Group':4}\n",
    "hotel_booking_f['customer_type'] = hotel_booking_f['customer_type'].map(mapping10)\n",
    "mapping11={'Check-Out':1,'Canceled':2,'No-Show':3}\n",
    "hotel_booking_f['reservation_status'] = hotel_booking_f['reservation_status'].map(mapping11)\n",
    "\n",
    "#热力图\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(25,25))\n",
    "sns.set()\n",
    "ax=sns.heatmap(hotel_booking_f.corr(), vmin=0.0001, vmax=None,cmap=None, center=None, robust=False, annot=True,\n",
    "               fmt='.1g', annot_kws=None,linewidths=0, linecolor='white', cbar=True, cbar_kws=None,\n",
    "               cbar_ax=None,square=False, xticklabels='auto', yticklabels='auto', mask=None, ax=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4、数据编码（不同于特征工程，在此对分类标签进行one-hot编码）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping1 = {'City Hotel': 0, 'Resort Hotel': 1}\n",
    "hotel_booking['hotel'] = hotel_booking['hotel'].map(mapping1)\n",
    "mapping2={'January':1,'February':2,'March':3,'April':4,'May':5,'June':6,\n",
    "          'July':7,'August':8,'September':9,'October':10,'November':11,'December':12}\n",
    "hotel_booking['arrival_date_month'] = hotel_booking['arrival_date_month'].map(mapping2)\n",
    "dummy1=pd.get_dummies(hotel_booking.pop('meal'),prefix='meal')\n",
    "dummy2=pd.get_dummies(hotel_booking.pop('country'),prefix='country')\n",
    "dummy3=pd.get_dummies(hotel_booking.pop('market_segment'),prefix='market_segment')\n",
    "dummy4=pd.get_dummies(hotel_booking.pop('distribution_channel'),prefix='distribution_channel')\n",
    "dummy5=pd.get_dummies(hotel_booking.pop('reserved_room_type'),prefix='reserved_room_type')\n",
    "dummy7=pd.get_dummies(hotel_booking.pop('deposit_type'),prefix='deposit_type')\n",
    "dummy8=pd.get_dummies(hotel_booking.pop('customer_type'),prefix='customer_type')\n",
    "dummy9=pd.get_dummies(hotel_booking.pop('reservation_status'),prefix='reservation_status')\n",
    "\n",
    "#把'reservation_status_date'中的字符串型的日期用pd.to_datetime(df.date)转化为日期格式，再用函数转化成年、月、日三列,数据类型为int\n",
    "reservation_status_date=hotel_booking.pop('reservation_status_date')\n",
    "reservation_status_date=pd.to_datetime(reservation_status_date)\n",
    "def get_date(date):\n",
    "    '''这里的输入date是一列年月日数据'''\n",
    "    Y, M, D = [], [], []\n",
    "    for i in range(len(date)):\n",
    "        oneday=date[i]\n",
    "        year=oneday.year\n",
    "        month=oneday.month\n",
    "        day=oneday.day\n",
    "\n",
    "        Y.append(year)\n",
    "        M.append(month)\n",
    "        D.append(day)\n",
    "    date=pd.DataFrame()\n",
    "    date['year']=Y\n",
    "    date['month']=M\n",
    "    date['day']=D\n",
    "    return date\n",
    "\n",
    "rsd_in_3colums=get_date(reservation_status_date)\n",
    "hotel_booking=pd.concat([hotel_booking,dummy1,dummy2,dummy3,dummy4,dummy5,dummy7,dummy8,dummy9,rsd_in_3colums],axis=1,ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 三、算法建模"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "划分训练集和测试集，7：3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=hotel_booking\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结果评估：用准确率和f1作为结果评价指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix,roc_auc_score,f1_score,recall_score,roc_curve,auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1、逻辑回归\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#分别探究模型迭代次数（max_iter）和损失函数优化器（solver）对模型性能的影响。以下是探究的是max_iter：\n",
    "def LR(solver):\n",
    "    '''构建逻辑回归模型,返回准确率,f1,运行时间'''\n",
    "    import time\n",
    "    start = time.time()\n",
    "    clf_lr = LogisticRegression(penalty='l2', solver=solver, random_state=0, max_iter=100)\n",
    "    clf_lr.fit(X_train, y_train)\n",
    "    y_pred_lr = clf_lr.predict(X_test)\n",
    "    \n",
    "    accuracy=accuracy_score(y_test, y_pred_lr)\n",
    "    f1=f1_score(y_test, y_pred_lr, labels=None, pos_label=1, average='weighted', sample_weight=None)\n",
    "    end = time.time()\n",
    "    return accuracy,f1,end-start\n",
    "\n",
    "solver_set=['saga','liblinear','newton-cg','lbfgs']#损失函数优化器集合\n",
    "accuracy_set=[]\n",
    "f1_set=[]\n",
    "time_set=[]\n",
    "for i in solver_set:\n",
    "    ac,f1,time=LR(i)\n",
    "    accuracy_set.append(ac)\n",
    "    f1_set.append(f1)\n",
    "    time_set.append(time)\n",
    "\n",
    "#可视化\n",
    "#accuracy，f1随不同损失函数优化器变化的折线图图\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.grid(visible=True, ls=':')\n",
    "plt.title('LR: solver Varying Accuracy&F1 Plot',fontsize=18)\n",
    "plt.plot(solver_set,accuracy_set,label='Accuracy',c='#20B2AA',lw=2,ls='dashed',mfc='#008080',marker='o',ms=8)\n",
    "plt.plot(solver_set,f1_set,label='F1',c='#483D8B',lw=2,ls='dashed',mfc='#4B0082',marker='s',ms=8)\n",
    "plt.xlabel('Solver Set', fontsize=16)\n",
    "plt.ylabel('Accuracy&F1', fontsize=16)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#time的图\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.grid(visible=True, ls=':')\n",
    "plt.title('LR: solver Varying Running Time Plot',fontsize=18)\n",
    "plt.plot(solver_set,time_set,label='Time',c='slateblue',lw=2,ls='dashed',mfc='slateblue',marker='o',ms=8)\n",
    "plt.xlabel('Min Samples Leaf', fontsize=16)\n",
    "plt.ylabel('Running Time', fontsize=16)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2、决策树（可视化的代码同上，略）\n",
    "#探究最大深度（max_depth）对决策树模型性能的影响\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "def decision_tree(max_depth):\n",
    "    '''构建决策树模型,返回准确率,f1,运行时间'''\n",
    "    import time\n",
    "    start = time.time()\n",
    "    clf_DTC=DecisionTreeClassifier(criterion='gini',max_depth=max_depth)\n",
    "    clf_DTC=clf_DTC.fit(X_train,y_train)\n",
    "    y_pred_test=clf_DTC.predict(X_test)\n",
    "\n",
    "    accuracy= accuracy_score(y_test, y_pred_test)\n",
    "    f1=f1_score(y_test, y_pred_test, average='weighted')\n",
    "    end = time.time()\n",
    "\n",
    "    return accuracy,f1,end-start\n",
    "\n",
    "max_depths=[]\n",
    "accuracy_set=[]\n",
    "f1_set=[]\n",
    "train_results = []\n",
    "test_results = []\n",
    "time_set=[]\n",
    "for i in range(1,101):\n",
    "    max_depths.append(i)\n",
    "    ac,f1=decision_tree(i)\n",
    "    accuracy_set.append(ac)\n",
    "    f1_set.append(f1)\n",
    "    time_set.append(time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3、随机森林（可视化的代码同上，略）\n",
    "#探究最大深度（max_depth）、分类器个数（n_estimators），以及“min_samples_leaf”& “min_samples_split” 对决策树模型性能的影响\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def Random_Forest_Classifier(max_depth):\n",
    "    '''构建随机森林模型,返回准确率,f1,训练集的ROC-AUC值,测试集的ROC-AUC值'''\n",
    "    import time\n",
    "    start = time.time()\n",
    "    clf_rf = RandomForestClassifier(n_estimators=80, max_depth=max_depth)\n",
    "    clf_rf.fit(X_train, y_train)\n",
    "    y_pred_rf = clf_rf.predict(X_test)\n",
    "    accuracy= accuracy_score(y_test, y_pred_rf)\n",
    "    f1=f1_score(y_test, y_pred_rf, average='weighted')\n",
    "    end = time.time()\n",
    "    return accuracy,f1,end-start\n",
    "\n",
    "max_depth=[]\n",
    "accuracy_set=[]\n",
    "f1_set=[]\n",
    "time_set=[]\n",
    "train_results = []\n",
    "test_results = []\n",
    "for i in range(1,101,5):\n",
    "    max_depth.append(i)\n",
    "    ac,f1,time=Random_Forest_Classifier(i)\n",
    "    accuracy_set.append(ac)\n",
    "    f1_set.append(f1)\n",
    "    time_set.append(time)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
